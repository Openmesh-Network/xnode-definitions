{
    "type": "package",
    "package_attr_name": "llama-cpp",
    "package_attr_set": "No package set",
    "package_pname": "llama-cpp",
    "package_pversion": "3403",
    "package_platforms": [
        "riscv32-netbsd",
        "mips-linux",
        "powerpc-netbsd",
        "x86_64-solaris",
        "armv6l-netbsd",
        "riscv32-linux",
        "s390-linux",
        "x86_64-linux",
        "x86_64-darwin",
        "aarch64-linux",
        "i686-openbsd",
        "microblaze-linux",
        "s390x-linux",
        "mipsel-netbsd",
        "i686-freebsd",
        "aarch64-netbsd",
        "x86_64-freebsd",
        "aarch64-darwin",
        "riscv64-netbsd",
        "powerpc64-linux",
        "mipsel-linux",
        "mips64-linux",
        "riscv64-linux",
        "armv7a-netbsd",
        "m68k-netbsd",
        "powerpc64le-linux",
        "i686-darwin",
        "microblazeel-linux",
        "mips64el-linux",
        "armv6l-linux",
        "x86_64-netbsd",
        "loongarch64-linux",
        "armv7l-linux",
        "m68k-linux",
        "i686-netbsd",
        "armv7a-linux",
        "armv5tel-linux",
        "x86_64-cygwin",
        "armv7l-netbsd",
        "i686-linux",
        "x86_64-openbsd",
        "x86_64-redox",
        "armv7a-darwin",
        "i686-cygwin"
    ],
    "package_outputs": [
        "out"
    ],
    "package_default_output": "out",
    "package_programs": [
        "test-chat-template",
        "llama-lookup-create",
        "llama-lookahead",
        "llama-bench-matmult",
        "llama-bench",
        "llama-batched-bench",
        "llama-batched",
        "llama-train-text-from-scratch",
        "llama-baby-llama",
        "llama-infill",
        "llama-cli",
        "convert_hf_to_gguf.py",
        "test-tokenizer-0",
        "llama-server",
        "llama-gbnf-validator",
        "llama-imatrix",
        "llama-save-load-state",
        "llama-convert-llama2c-to-ggml",
        "llama-quantize-stats",
        "llama-finetune",
        "test-grad0",
        "llama-quantize",
        "llama-gguf-hash",
        "llama-embedding",
        "llama",
        "test-sampling",
        "llama-perplexity",
        "test-rope",
        "llama-lookup",
        "test-quantize-perf",
        "llama-lookup-stats",
        "llama-retrieval",
        "llama-speculative",
        "llama-lookup-merge",
        "test-grammar-integration",
        "test-quantize-fns",
        "test-model-load-cancel",
        "test-grammar-parser",
        "test-llama-grammar",
        "test-backend-ops",
        "test-tokenizer-1-bpe",
        "llama-tokenize",
        "test-autorelease",
        "llama-llava-cli",
        "llama-parallel",
        "llama-gritlm",
        "llama-gguf-split",
        "llama-gguf",
        "llama-export-lora",
        "test-tokenizer-1-spm",
        "llama-simple",
        "test-json-schema-to-grammar",
        "llama-eval-callback",
        "llama-cvector-generator",
        "llama-passkey"
    ],
    "package_license": [
        {
            "url": "https://spdx.org/licenses/MIT.html",
            "fullName": "MIT License"
        }
    ],
    "package_license_set": [
        "MIT License"
    ],
    "package_maintainers": [
        {
            "name": "Mostly Void",
            "github": "dit7ya",
            "email": "7rat13@gmail.com"
        },
        {
            "name": "Enno Lohmeier",
            "github": "elohmeier",
            "email": "elo-nixos@nerdworks.de"
        },
        {
            "name": "Philip Taron",
            "github": "philiptaron",
            "email": "philip.taron@gmail.com"
        }
    ],
    "package_maintainers_set": [
        "Mostly Void",
        "Enno Lohmeier",
        "Philip Taron"
    ],
    "package_description": "Port of Facebook's LLaMA model in C/C++",
    "package_longDescription": null,
    "package_hydra": null,
    "package_system": "x86_64-linux",
    "package_homepage": [
        "https://github.com/ggerganov/llama.cpp/"
    ],
    "package_position": "pkgs/by-name/ll/llama-cpp/package.nix:157"
}