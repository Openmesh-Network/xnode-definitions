{
    "type": "package",
    "package_attr_name": "hadoop",
    "package_attr_set": "No package set",
    "package_pname": "hadoop",
    "package_pversion": "3.3.6",
    "package_platforms": [
        "x86_64-darwin",
        "aarch64-linux",
        "x86_64-linux",
        "aarch64-darwin"
    ],
    "package_outputs": [
        "out"
    ],
    "package_default_output": "out",
    "package_programs": [
        "mr-jobhistory-daemon.sh",
        "test-container-executor",
        "mapred.cmd",
        "start-balancer.sh",
        "hadoop",
        "start-all.sh",
        "stop-dfs.sh",
        "mapred",
        "start-yarn.sh",
        "container-executor",
        "stop-yarn.sh",
        "start-dfs.cmd",
        "hadoop.cmd",
        "refresh-namenodes.sh",
        "start-yarn.cmd",
        "start-dfs.sh",
        "oom-listener",
        "stop-secure-dns.sh",
        "kms.sh",
        "yarn-daemons.sh",
        "httpfs.sh",
        "yarn-daemon.sh",
        "stop-all.sh",
        "hadoop-daemons.sh",
        "stop-balancer.sh",
        "start-secure-dns.sh",
        "yarn",
        "start-all.cmd",
        "stop-all.cmd",
        "yarn.cmd",
        "stop-yarn.cmd",
        "stop-dfs.cmd",
        "hdfs.cmd",
        "hadoop-daemon.sh",
        "workers.sh",
        "distribute-exclude.sh",
        "hdfs"
    ],
    "package_license": [
        {
            "url": "https://spdx.org/licenses/Apache-2.0.html",
            "fullName": "Apache License 2.0"
        }
    ],
    "package_license_set": [
        "Apache License 2.0"
    ],
    "package_maintainers": [
        {
            "name": "Harikrishnan R",
            "github": "illustris",
            "email": "me@illustris.tech"
        }
    ],
    "package_maintainers_set": [
        "Harikrishnan R"
    ],
    "package_description": "Framework for distributed processing of large data sets across clusters of computers",
    "package_longDescription": "<rendered-html><p>The Apache Hadoop software library is a framework that allows for the\ndistributed processing of large data sets across clusters of computers\nusing a simple programming model. It is designed to scale up from single\nservers to thousands of machines, each offering local computation and\nstorage. Rather than rely on hardware to deliver high-avaiability, the\nlibrary itself is designed to detect and handle failures at the\napplication layer, so delivering a highly-availabile service on top of a\ncluster of computers, each of which may be prone to failures.</p>\n</rendered-html>",
    "package_hydra": null,
    "package_system": "x86_64-linux",
    "package_homepage": [
        "https://hadoop.apache.org/"
    ],
    "package_position": null
}